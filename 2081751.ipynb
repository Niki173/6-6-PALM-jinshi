{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：PALM病理性近视预测6月第6名方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**此方案来自大佬的方案，并在这基础上做了一些新的尝试。基线地址：**\n",
    "\n",
    "https://aistudio.baidu.com/aistudio/projectdetail/2020177?channelType=0&channel=0\n",
    "\n",
    "本人有幸获得第6名\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e409b08e076b4a16b1a5295ec8c33efbd24a6aefe630420d924ced26cbacc05b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **一、赛题介绍**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 赛题介绍\n",
    "常规赛：PALM病理性近视预测由ISBI2019 PALM眼科挑战赛赛题再现，其中病理性近视预测的任务旨在对眼科图像进行判断，获得该眼为病理性近视的概率。\n",
    "\n",
    "数据集由中山大学中山眼科中心提供800张带病理性近视分类标注的眼底彩照供选手训练模型，另提供400张带标注数据供平台进行模型测试。图像分辨率为1444×1444，或2124×2056。\n",
    "\n",
    "评价指标为AUC (Area Under Curve)，即ROC (Receiver operating characteristic) 曲线与坐标轴形成的面积。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/64afb1df4595408088e547b616423f447e5761ae13224ca4be559b0c598d598b)\n",
    "\n",
    "比赛链接: [常规赛：PALM病理性近视预测](https://aistudio.baidu.com/aistudio/competition/detail/85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **2.数据简介**\n",
    "PALM病理性近视预测常规赛由中山大学中山眼科中心提供800张带病理性近视分类标注的眼底彩照供选手训练模型，另提供400张带标注数据供平台进行模型测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **3. 训练数据集**\n",
    "\n",
    "文件名称：Train Train文件夹里有一个fundus_image文件夹和一个Classification.xlsx文件。fundus_image文件夹中数据均为眼底彩照，分辨率为1444×1444，或2124×2056。命名形如N0001.jpg、H0001.jpg、P0001.jpg和V0001.jpg。Classification.xlsx文件中为各眼底图像是否属于病理性近视，属于为1，不属于为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **4.测试数据集**\n",
    "文件名称：PALM-Testing400-Images 文件夹里包含400张眼底彩照，命名形如T0001.jpg。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **5.提交内容及格式**\n",
    "分类结果应在一个名为“Classification_Results.csv”的CSV文件中提供，第一列对应测试眼底图像的文件名(包括扩展名“.jpg”)，对应title为FileName；第二列包含诊断为PM的患者图像的分类预测概率(值从0.0到1.0)，对应title为PM Risk。示例如下：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/942be68153dc4c7eb4c0ac8c5b3dc4f19e083ee0ec75479a87a7c385296fbdee)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **二、个人思路**\n",
    "\n",
    "对训练集进行8：2的划分，然后对图片进行resize1024x1024，1120x1120的尺度下进行训练，数据增强加上了垂直翻转以及随机旋转，以及对学习率lr进行了不同的训练，从而得到不同的模型权重再进行测试，测试完后再进行结果融合。\n",
    "\n",
    "**新增点：**\n",
    "\n",
    "增加垂直翻转以及随机旋转，不同尺度+不同学习率\n",
    "\n",
    "**创新点：**\n",
    "\n",
    "结果融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **三、前期准备**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 包准备\n",
    "既然是分类任务，首先想到的是PaddleClas。但是我忽然想到了大佬们搞的ppim。因为医疗影像我认为有重要的关注的地方，和遥感图像不太类似，注意力应该能取得较好的效果。听闻大佬们的ppim复现了很新的注意力网络，而且和源代码相比效果很好，所以决定试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip -q install ppim -i https://pypi.python.org/pypi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 数据准备\n",
    "### 2.1解压数据集\n",
    "这个没啥好写的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! unzip -oq  /home/aistudio/data/data93465/常规赛：PALM病理性近视预测.zip\r\n",
    "# ! rm -rf __MACOSX\r\n",
    "# ! mv 常规赛：PALM病理性近视预测 PLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 配置数据集\n",
    "- 因为数据中本身就有了这个图像名和标签，我们就不用生成数据列表了。直接继承io中的Dataset，用于读取数据。因为与开始说数据的大小有两种分辨率，而且贼大，但是又不敢放的太小损失太多细节，所以这里都放到了1120X1120（也做了1024x1024尺度的尝试，发现1120x1120效果更好）。\n",
    "- 划分的比列为0.8，图像增强再原有的基础上增加了垂直翻转以及随机翻转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "import paddle.vision.transforms as T\r\n",
    "from paddle.io import Dataset\r\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PLAMDatas(Dataset):\r\n",
    "    def __init__(self, data_path, class_xls, mode='train', transforms=None):\r\n",
    "        super(PLAMDatas, self).__init__()\r\n",
    "        self.data_path = data_path\r\n",
    "        self.name_label = (pd.read_excel(class_xls)).values\r\n",
    "        lens = len(self.name_label)\r\n",
    "        if mode == 'train':\r\n",
    "            self.name_label = self.name_label[:int(0.8*lens)]\r\n",
    "        else:\r\n",
    "            self.name_label = self.name_label[int(0.8*lens):]\r\n",
    "        self.transforms = transforms\r\n",
    "        \r\n",
    "    def __getitem__(self, index):\r\n",
    "        name, label = self.name_label[index]\r\n",
    "        data_path = os.path.join(self.data_path, name)\r\n",
    "        data = np.asarray(Image.open(data_path).convert('RGB'))\r\n",
    "        if self.transforms is not None:\r\n",
    "            data = self.transforms(data)\r\n",
    "        data = data.astype('float32')\r\n",
    "        label = np.array(int(label)).astype('int64')\r\n",
    "        return data, label\r\n",
    "        \r\n",
    "    def __len__(self):\r\n",
    "        return len(self.name_label)\r\n",
    "\r\n",
    "# 配置数据增广\r\n",
    "train_transforms = T.Compose([\r\n",
    "\r\n",
    "    T.Resize((1120, 1120), interpolation='bicubic'),\r\n",
    "    T.ColorJitter(0.1, 0.1, 0.1, 0.1),\r\n",
    "    T.RandomHorizontalFlip(),\r\n",
    "    T.RandomVerticalFlip(),\r\n",
    "    T.RandomRotation(90),\r\n",
    "   \tT.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "val_transforms = T.Compose([\r\n",
    "    T.Resize((1120, 1120), interpolation='bicubic'),\r\n",
    "    T.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "# 配置数据集\r\n",
    "train_dataset = PLAMDatas(data_path='PLAM/Train/fundus_image', class_xls='PLAM/Train/Classification.xlsx', mode='train', transforms=train_transforms)\r\n",
    "val_dataset = PLAMDatas(data_path='PLAM/Train/fundus_image', class_xls='PLAM/Train/Classification.xlsx', mode='test', transforms=val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这里也是输出测试一下，看看数据读取有没有什么问题。避免后面报一堆错不知道哪儿去找问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 160\n",
      "[3, 1120, 1120] 0\n",
      "[3, 1120, 1120] 0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset))\r\n",
    "for img, lab in train_dataset:\r\n",
    "    print(img.shape, lab)\r\n",
    "    break\r\n",
    "for img ,lab in val_dataset:\r\n",
    "    print(img.shape, lab)\r\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **四、开始训练**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.模型准备\n",
    "基础的DistilledVisionTransformer，自己说用1120的。但是这样就没有预训练的参数了，只能自己跑了。patch_size也改了一下，太小的话空间占用多，运算慢，而且不太好。summary看一下，总算没问题了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Conv2D-8     [[1, 3, 1120, 1120]]   [1, 768, 17, 17]      9,437,952   \n",
      " PatchEmbed-4   [[1, 3, 1120, 1120]]    [1, 289, 768]            0       \n",
      "  Dropout-112     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-76     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-151      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-113   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-152      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-114     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-37     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-37     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-77     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-153      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-37       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-115     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-154      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-37        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-37       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-78     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-155      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-116   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-156      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-117     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-38     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-38     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-79     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-157      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-38       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-118     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-158      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-38        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-38       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-80     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-159      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-119   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-160      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-120     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-39     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-39     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-81     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-161      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-39       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-121     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-162      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-39        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-39       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-82     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-163      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-122   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-164      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-123     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-40     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-40     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-83     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-165      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-40       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-124     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-166      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-40        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-40       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-84     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-167      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-125   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-168      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-126     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-41     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-41     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-85     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-169      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-41       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-127     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-170      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-41        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-41       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-86     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-171      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-128   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-172      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-129     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-42     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-42     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-87     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-173      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-42       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-130     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-174      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-42        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-42       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-88     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-175      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-131   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-176      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-132     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-43     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-43     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-89     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-177      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-43       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-133     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-178      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-43        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-43       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-90     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-179      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-134   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-180      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-135     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-44     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-44     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-91     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-181      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-44       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-136     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-182      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-44        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-44       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-92     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-183      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-137   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-184      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-138     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-45     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-45     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-93     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-185      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-45       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-139     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-186      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-45        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-45       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-94     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-187      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-140   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-188      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-141     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-46     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-46     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-95     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-189      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-46       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-142     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-190      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-46        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-46       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-96     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-191      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-143   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-192      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-144     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-47     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-47     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-97     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-193      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-47       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-145     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-194      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-47        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-47       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-98     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-195      [[1, 291, 768]]       [1, 291, 2304]       1,769,472   \n",
      "  Dropout-146   [[1, 12, 291, 291]]   [1, 12, 291, 291]          0       \n",
      "  Linear-196      [[1, 291, 768]]       [1, 291, 768]         590,592    \n",
      "  Dropout-147     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " Attention-48     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Identity-48     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-99     [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-197      [[1, 291, 768]]       [1, 291, 3072]       2,362,368   \n",
      "    GELU-48       [[1, 291, 3072]]      [1, 291, 3072]           0       \n",
      "  Dropout-148     [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "  Linear-198      [[1, 291, 3072]]      [1, 291, 768]        2,360,064   \n",
      "    Mlp-48        [[1, 291, 768]]       [1, 291, 768]            0       \n",
      "   Block-48       [[1, 291, 768]]       [1, 291, 768]            0       \n",
      " LayerNorm-100    [[1, 291, 768]]       [1, 291, 768]          1,536     \n",
      "  Linear-199         [[1, 768]]             [1, 2]             1,538     \n",
      "  Linear-200         [[1, 768]]             [1, 2]             1,538     \n",
      "===========================================================================\n",
      "Total params: 94,469,380\n",
      "Trainable params: 94,469,380\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 14.36\n",
      "Forward/backward pass size (MB): 529.51\n",
      "Params size (MB): 360.37\n",
      "Estimated Total Size (MB): 904.24\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from ppim import DistilledVisionTransformer\r\n",
    "\r\n",
    "# 模型定义\r\n",
    "model = DistilledVisionTransformer(\r\n",
    "    img_size=1120,\r\n",
    "    patch_size=64,\r\n",
    "    class_dim=2)\r\n",
    "params = paddle.load('save_models5/final.pdparams')\r\n",
    "model.set_state_dict(params)\r\n",
    "paddle.summary(model, (1, 3, 1120, 1120))\r\n",
    "model = paddle.Model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 .开始训练\n",
    "这里进行两次不同优化器的训练，首先用Adam跑了100epochs，让模型更快的收敛，然后再用SGD跑50epochs进行降loss。\n",
    "\n",
    "使用了不同的学习率配合不同的优化器进行训练\n",
    "\n",
    "1. CosineAnnealingDecay + Adam + bs64\n",
    "2. PolynomialDecay + SGD + ClipGradByGlobalNorm + bs8\n",
    "\n",
    "注:checkpiont放在save_models*文件夹里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20/20 [==============================] - loss: 0.2596 - acc: 0.9406 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/0\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1552 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 2/50\n",
      "step 20/20 [==============================] - loss: 0.1823 - acc: 0.9484 - 5s/step        \n",
      "Epoch 3/50\n",
      "step 20/20 [==============================] - loss: 0.1013 - acc: 0.9484 - 5s/step        \n",
      "Epoch 4/50\n",
      "step 20/20 [==============================] - loss: 0.0713 - acc: 0.9453 - 5s/step        \n",
      "Epoch 5/50\n",
      "step 20/20 [==============================] - loss: 0.1338 - acc: 0.9594 - 5s/step        \n",
      "Epoch 6/50\n",
      "step 20/20 [==============================] - loss: 0.0655 - acc: 0.9484 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/5\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1552 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 7/50\n",
      "step 20/20 [==============================] - loss: 0.1948 - acc: 0.9516 - 5s/step        \n",
      "Epoch 8/50\n",
      "step 20/20 [==============================] - loss: 0.0841 - acc: 0.9453 - 5s/step        \n",
      "Epoch 9/50\n",
      "step 20/20 [==============================] - loss: 0.1742 - acc: 0.9375 - 5s/step        \n",
      "Epoch 10/50\n",
      "step 20/20 [==============================] - loss: 0.0391 - acc: 0.9469 - 5s/step        \n",
      "Epoch 11/50\n",
      "step 20/20 [==============================] - loss: 0.0913 - acc: 0.9406 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/10\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1549 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 12/50\n",
      "step 20/20 [==============================] - loss: 0.1393 - acc: 0.9344 - 5s/step        \n",
      "Epoch 13/50\n",
      "step 20/20 [==============================] - loss: 0.0299 - acc: 0.9594 - 5s/step        \n",
      "Epoch 14/50\n",
      "step 20/20 [==============================] - loss: 0.2839 - acc: 0.9359 - 5s/step        \n",
      "Epoch 15/50\n",
      "step 20/20 [==============================] - loss: 0.2167 - acc: 0.9563 - 5s/step        \n",
      "Epoch 16/50\n",
      "step 20/20 [==============================] - loss: 0.1177 - acc: 0.9453 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/15\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1547 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 17/50\n",
      "step 20/20 [==============================] - loss: 0.0791 - acc: 0.9453 - 5s/step        \n",
      "Epoch 18/50\n",
      "step 20/20 [==============================] - loss: 0.0830 - acc: 0.9516 - 5s/step        \n",
      "Epoch 19/50\n",
      "step 20/20 [==============================] - loss: 0.2218 - acc: 0.9547 - 5s/step        \n",
      "Epoch 20/50\n",
      "step 20/20 [==============================] - loss: 0.0631 - acc: 0.9422 - 5s/step        \n",
      "Epoch 21/50\n",
      "step 20/20 [==============================] - loss: 0.1365 - acc: 0.9469 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/20\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1542 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 22/50\n",
      "step 20/20 [==============================] - loss: 0.1628 - acc: 0.9484 - 5s/step        \n",
      "Epoch 23/50\n",
      "step 20/20 [==============================] - loss: 0.0346 - acc: 0.9453 - 5s/step        \n",
      "Epoch 24/50\n",
      "step 20/20 [==============================] - loss: 0.0679 - acc: 0.9453 - 5s/step        \n",
      "Epoch 25/50\n",
      "step 20/20 [==============================] - loss: 0.0680 - acc: 0.9500 - 5s/step        \n",
      "Epoch 26/50\n",
      "step 20/20 [==============================] - loss: 0.0417 - acc: 0.9469 - 5s/step        \n",
      "save checkpoint at /home/aistudio/save_models7/25\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 5/5 [==============================] - loss: 0.1544 - acc: 0.9625 - 3s/step         \n",
      "Eval samples: 160\n",
      "Epoch 27/50\n",
      "step 20/20 [==============================] - loss: 0.1517 - acc: 0.9484 - 5s/step        \n",
      "Epoch 28/50\n",
      "step 20/20 [==============================] - loss: 0.2064 - acc: 0.9500 - 5s/step        \n",
      "Epoch 29/50\n",
      "step 15/20 [=====================>........] - loss: 0.0643 - acc: 0.9375 - ETA: 23s - 5s/st"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-91e7819be027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvisualdl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks)\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36m_run_one_epoch\u001b[0;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m             \u001b[0;31m# data might come from different types of data_loader and have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0;31m# different format, as following:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0min_dygraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_next_var_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # 模型准备\r\n",
    "# lr = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=0.00000001, T_max=int(2*(800*0.9)), verbose=False)\r\n",
    "# opt = paddle.optimizer.Adam(learning_rate=lr, parameters=model.parameters(), weight_decay=paddle.regularizer.L2Decay(1e-7))\r\n",
    "\r\n",
    "\r\n",
    "lr = paddle.optimizer.lr.PolynomialDecay(learning_rate=3e-9, decay_steps=1000)\r\n",
    "opt = paddle.optimizer.SGD(learning_rate=lr, parameters=model.parameters(), \\\r\n",
    "                           weight_decay=paddle.regularizer.L2Decay(1e-9), grad_clip=paddle.nn.ClipGradByGlobalNorm(clip_norm=1.0))\r\n",
    "                           \r\n",
    "# last\r\n",
    "# opt_params = paddle.load('save_models/85.pdparams')\r\n",
    "# opt.set_state_dict(opt_params)\r\n",
    "loss = nn.CrossEntropyLoss()\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "model.prepare(optimizer=opt, loss=loss, metrics=metric)\r\n",
    "visualdl=paddle.callbacks.VisualDL(log_dir='visual_log')\r\n",
    "\r\n",
    "# 模型微调\r\n",
    "model.fit(\r\n",
    "    train_data=train_dataset, \r\n",
    "    eval_data=val_dataset, \r\n",
    "    batch_size=32, \r\n",
    "    epochs=50,\r\n",
    "    eval_freq=5,\r\n",
    "    log_freq=1, \r\n",
    "    save_dir='save_models7', \r\n",
    "    save_freq=5,\r\n",
    "    verbose=1, \r\n",
    "    drop_last=True, \r\n",
    "    shuffle=True,\r\n",
    "    num_workers=0,\r\n",
    "    callbacks=[visualdl]\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **五、预测结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. 模型预测\n",
    "- 结果必须升序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T0103.jpg', 0.012307137]\n",
      "['T0210.jpg', 0.90871423]\n",
      "['T0323.jpg', 0.014455602]\n",
      "['T0134.jpg', 0.9990803]\n",
      "['T0066.jpg', 0.9962853]\n",
      "['T0001.jpg', 0.99403954]\n",
      "['T0225.jpg', 0.45718023]\n",
      "['T0286.jpg', 0.041713268]\n",
      "['T0209.jpg', 0.99929214]\n",
      "['T0233.jpg', 0.03114533]\n",
      "['T0366.jpg', 0.059233658]\n",
      "['T0202.jpg', 0.0029475705]\n",
      "['T0278.jpg', 0.99712855]\n",
      "['T0398.jpg', 0.9990043]\n",
      "['T0078.jpg', 0.0048059905]\n",
      "['T0270.jpg', 0.9877489]\n",
      "['T0289.jpg', 0.81314903]\n",
      "['T0232.jpg', 0.8559369]\n",
      "['T0253.jpg', 0.1409466]\n",
      "['T0330.jpg', 0.0064832186]\n",
      "['T0043.jpg', 0.6406758]\n",
      "['T0370.jpg', 0.9222939]\n",
      "['T0172.jpg', 0.99530596]\n",
      "['T0061.jpg', 0.86990035]\n",
      "['T0167.jpg', 0.9949851]\n",
      "['T0349.jpg', 0.94388616]\n",
      "['T0360.jpg', 0.9947523]\n",
      "['T0333.jpg', 0.0065847537]\n",
      "['T0297.jpg', 0.20527397]\n",
      "['T0053.jpg', 0.012088187]\n",
      "['T0228.jpg', 0.005353403]\n",
      "['T0127.jpg', 0.9989631]\n",
      "['T0381.jpg', 0.003037737]\n",
      "['T0344.jpg', 0.9908296]\n",
      "['T0352.jpg', 0.9854972]\n",
      "['T0189.jpg', 0.012986695]\n",
      "['T0100.jpg', 0.49359265]\n",
      "['T0341.jpg', 0.9996692]\n",
      "['T0075.jpg', 0.988863]\n",
      "['T0155.jpg', 0.9964135]\n",
      "['T0363.jpg', 0.0060812817]\n",
      "['T0348.jpg', 0.014048084]\n",
      "['T0342.jpg', 0.9625817]\n",
      "['T0195.jpg', 0.024826797]\n",
      "['T0101.jpg', 0.9888676]\n",
      "['T0098.jpg', 0.006875737]\n",
      "['T0240.jpg', 0.9979242]\n",
      "['T0088.jpg', 0.99905545]\n",
      "['T0380.jpg', 0.99453235]\n",
      "['T0388.jpg', 0.99704665]\n",
      "['T0145.jpg', 0.9911226]\n",
      "['T0264.jpg', 0.99188095]\n",
      "['T0223.jpg', 0.9976922]\n",
      "['T0161.jpg', 0.0042887377]\n",
      "['T0249.jpg', 0.041713268]\n",
      "['T0125.jpg', 0.008596284]\n",
      "['T0245.jpg', 0.0027808247]\n",
      "['T0235.jpg', 0.9640827]\n",
      "['T0128.jpg', 0.0046273167]\n",
      "['T0356.jpg', 0.99967635]\n",
      "['T0049.jpg', 0.004271026]\n",
      "['T0331.jpg', 0.0023279174]\n",
      "['T0143.jpg', 0.99773645]\n",
      "['T0159.jpg', 0.9938677]\n",
      "['T0164.jpg', 0.02227682]\n",
      "['T0018.jpg', 0.9953727]\n",
      "['T0130.jpg', 0.99125236]\n",
      "['T0379.jpg', 0.32696337]\n",
      "['T0396.jpg', 0.9985089]\n",
      "['T0306.jpg', 0.9989856]\n",
      "['T0325.jpg', 0.99018186]\n",
      "['T0237.jpg', 0.90604925]\n",
      "['T0083.jpg', 0.014882003]\n",
      "['T0378.jpg', 0.9318351]\n",
      "['T0169.jpg', 0.0056458474]\n",
      "['T0367.jpg', 0.97292185]\n",
      "['T0221.jpg', 0.9944206]\n",
      "['T0218.jpg', 0.9934394]\n",
      "['T0208.jpg', 0.99853826]\n",
      "['T0204.jpg', 0.1071738]\n",
      "['T0138.jpg', 0.022080075]\n",
      "['T0151.jpg', 0.9974043]\n",
      "['T0285.jpg', 0.027035022]\n",
      "['T0007.jpg', 0.9691701]\n",
      "['T0256.jpg', 0.9978497]\n",
      "['T0124.jpg', 0.99929154]\n",
      "['T0097.jpg', 0.9820868]\n",
      "['T0206.jpg', 0.9365295]\n",
      "['T0386.jpg', 0.0063389153]\n",
      "['T0190.jpg', 0.99441886]\n",
      "['T0393.jpg', 0.98954517]\n",
      "['T0293.jpg', 0.4904263]\n",
      "['T0129.jpg', 0.0092371395]\n",
      "['T0152.jpg', 0.6182722]\n",
      "['T0294.jpg', 0.0034201415]\n",
      "['T0346.jpg', 0.99016273]\n",
      "['T0081.jpg', 0.97668046]\n",
      "['T0135.jpg', 0.012650938]\n",
      "['T0199.jpg', 0.0036549224]\n",
      "['T0042.jpg', 0.0036783481]\n",
      "['T0371.jpg', 0.9986505]\n",
      "['T0215.jpg', 0.0030058057]\n",
      "['T0198.jpg', 0.99354964]\n",
      "['T0383.jpg', 0.015317332]\n",
      "['T0089.jpg', 0.02961307]\n",
      "['T0051.jpg', 0.9969121]\n",
      "['T0072.jpg', 0.9770388]\n",
      "['T0132.jpg', 0.35218227]\n",
      "['T0357.jpg', 0.0054225056]\n",
      "['T0073.jpg', 0.9974681]\n",
      "['T0108.jpg', 0.0017424703]\n",
      "['T0006.jpg', 0.032943066]\n",
      "['T0034.jpg', 0.9992411]\n",
      "['T0170.jpg', 0.9968561]\n",
      "['T0117.jpg', 0.037716474]\n",
      "['T0163.jpg', 0.009565333]\n",
      "['T0160.jpg', 0.9987942]\n",
      "['T0109.jpg', 0.9285462]\n",
      "['T0384.jpg', 0.0019926557]\n",
      "['T0316.jpg', 0.014468454]\n",
      "['T0283.jpg', 0.0026753393]\n",
      "['T0147.jpg', 0.0055694627]\n",
      "['T0211.jpg', 0.99816245]\n",
      "['T0326.jpg', 0.8106482]\n",
      "['T0021.jpg', 0.0043539344]\n",
      "['T0274.jpg', 0.0019926443]\n",
      "['T0070.jpg', 0.006429946]\n",
      "['T0118.jpg', 0.01532629]\n",
      "['T0008.jpg', 0.9956103]\n",
      "['T0303.jpg', 0.9970797]\n",
      "['T0005.jpg', 0.99958795]\n",
      "['T0359.jpg', 0.98856807]\n",
      "['T0335.jpg', 0.005843663]\n",
      "['T0153.jpg', 0.9829836]\n",
      "['T0032.jpg', 0.012693948]\n",
      "['T0002.jpg', 0.008706468]\n",
      "['T0282.jpg', 0.99927217]\n",
      "['T0375.jpg', 0.99264]\n",
      "['T0395.jpg', 0.996064]\n",
      "['T0156.jpg', 0.011284045]\n",
      "['T0364.jpg', 0.99578214]\n",
      "['T0203.jpg', 0.99945015]\n",
      "['T0358.jpg', 0.0042363764]\n",
      "['T0027.jpg', 0.022977568]\n",
      "['T0013.jpg', 0.9843315]\n",
      "['T0184.jpg', 0.005673417]\n",
      "['T0262.jpg', 0.008459427]\n",
      "['T0136.jpg', 0.9936527]\n",
      "['T0354.jpg', 0.9984518]\n",
      "['T0251.jpg', 0.99388677]\n",
      "['T0312.jpg', 0.9796642]\n",
      "['T0305.jpg', 0.006247103]\n",
      "['T0260.jpg', 0.9955537]\n",
      "['T0369.jpg', 0.9966748]\n",
      "['T0024.jpg', 0.01631227]\n",
      "['T0231.jpg', 0.9990877]\n",
      "['T0039.jpg', 0.005910738]\n",
      "['T0188.jpg', 0.9891818]\n",
      "['T0030.jpg', 0.5582529]\n",
      "['T0037.jpg', 0.99104017]\n",
      "['T0271.jpg', 0.88482565]\n",
      "['T0146.jpg', 0.74678165]\n",
      "['T0399.jpg', 0.004941897]\n",
      "['T0062.jpg', 0.31416857]\n",
      "['T0197.jpg', 0.005576762]\n",
      "['T0304.jpg', 0.0076878434]\n",
      "['T0158.jpg', 0.98628354]\n",
      "['T0290.jpg', 0.0032549826]\n",
      "['T0040.jpg', 0.005555278]\n",
      "['T0045.jpg', 0.010184213]\n",
      "['T0192.jpg', 0.00912006]\n",
      "['T0035.jpg', 0.99029607]\n",
      "['T0010.jpg', 0.9446918]\n",
      "['T0015.jpg', 0.98728323]\n",
      "['T0173.jpg', 0.66700286]\n",
      "['T0258.jpg', 0.013071186]\n",
      "['T0259.jpg', 0.009702688]\n",
      "['T0248.jpg', 0.015852554]\n",
      "['T0308.jpg', 0.011607478]\n",
      "['T0200.jpg', 0.004090931]\n",
      "['T0263.jpg', 0.98573107]\n",
      "['T0082.jpg', 0.9970697]\n",
      "['T0150.jpg', 0.14695121]\n",
      "['T0382.jpg', 0.009729083]\n",
      "['T0023.jpg', 0.99892056]\n",
      "['T0319.jpg', 0.998348]\n",
      "['T0092.jpg', 0.9991321]\n",
      "['T0168.jpg', 0.00320495]\n",
      "['T0373.jpg', 0.82973117]\n",
      "['T0353.jpg', 0.9564352]\n",
      "['T0277.jpg', 0.0075759506]\n",
      "['T0309.jpg', 0.0058495114]\n",
      "['T0295.jpg', 0.012408653]\n",
      "['T0057.jpg', 0.0040142527]\n",
      "['T0329.jpg', 0.99448806]\n",
      "['T0069.jpg', 0.99961036]\n",
      "['T0255.jpg', 0.0028884285]\n",
      "['T0054.jpg', 0.99931216]\n",
      "['T0114.jpg', 0.909846]\n",
      "['T0207.jpg', 0.99956673]\n",
      "['T0099.jpg', 0.009157534]\n",
      "['T0048.jpg', 0.011029246]\n",
      "['T0324.jpg', 0.043156046]\n",
      "['T0110.jpg', 0.9398]\n",
      "['T0140.jpg', 0.41833097]\n",
      "['T0176.jpg', 0.99902797]\n",
      "['T0281.jpg', 0.0027148237]\n",
      "['T0113.jpg', 0.9995338]\n",
      "['T0031.jpg', 0.032938343]\n",
      "['T0084.jpg', 0.002748082]\n",
      "['T0201.jpg', 0.44248122]\n",
      "['T0036.jpg', 0.9984432]\n",
      "['T0122.jpg', 0.99834347]\n",
      "['T0338.jpg', 0.9848583]\n",
      "['T0139.jpg', 0.99932444]\n",
      "['T0337.jpg', 0.011126147]\n",
      "['T0080.jpg', 0.96117043]\n",
      "['T0230.jpg', 0.048461378]\n",
      "['T0121.jpg', 0.004908861]\n",
      "['T0280.jpg', 0.005168128]\n",
      "['T0041.jpg', 0.9348274]\n",
      "['T0292.jpg', 0.010027099]\n",
      "['T0106.jpg', 0.99573743]\n",
      "['T0345.jpg', 0.9953497]\n",
      "['T0026.jpg', 0.9908313]\n",
      "['T0068.jpg', 0.005791885]\n",
      "['T0318.jpg', 0.07624159]\n",
      "['T0123.jpg', 0.9760375]\n",
      "['T0239.jpg', 0.40348646]\n",
      "['T0266.jpg', 0.95396376]\n",
      "['T0149.jpg', 0.003278371]\n",
      "['T0186.jpg', 0.009532422]\n",
      "['T0261.jpg', 0.9983719]\n",
      "['T0321.jpg', 0.9940409]\n",
      "['T0055.jpg', 0.9593526]\n",
      "['T0102.jpg', 0.99894744]\n",
      "['T0241.jpg', 0.999464]\n",
      "['T0071.jpg', 0.8933397]\n",
      "['T0275.jpg', 0.9008998]\n",
      "['T0087.jpg', 0.99949574]\n",
      "['T0205.jpg', 0.01924535]\n",
      "['T0020.jpg', 0.9926979]\n",
      "['T0276.jpg', 0.99175006]\n",
      "['T0074.jpg', 0.99756926]\n",
      "['T0093.jpg', 0.014209201]\n",
      "['T0079.jpg', 0.9996364]\n",
      "['T0142.jpg', 0.8089228]\n",
      "['T0214.jpg', 0.0044559627]\n",
      "['T0187.jpg', 0.0024519546]\n",
      "['T0148.jpg', 0.999198]\n",
      "['T0315.jpg', 0.9996402]\n",
      "['T0064.jpg', 0.9980636]\n",
      "['T0144.jpg', 0.0031895349]\n",
      "['T0362.jpg', 0.00707871]\n",
      "['T0171.jpg', 0.007894516]\n",
      "['T0355.jpg', 0.22488086]\n",
      "['T0361.jpg', 0.00599946]\n",
      "['T0185.jpg', 0.013359403]\n",
      "['T0090.jpg', 0.075160824]\n",
      "['T0120.jpg', 0.025499515]\n",
      "['T0193.jpg', 0.016092822]\n",
      "['T0389.jpg', 0.016682131]\n",
      "['T0334.jpg', 0.014079788]\n",
      "['T0340.jpg', 0.99088824]\n",
      "['T0250.jpg', 0.9972608]\n",
      "['T0091.jpg', 0.99847704]\n",
      "['T0387.jpg', 0.99814475]\n",
      "['T0028.jpg', 0.0064003114]\n",
      "['T0314.jpg', 0.9893056]\n",
      "['T0247.jpg', 0.0023256307]\n",
      "['T0288.jpg', 0.9986797]\n",
      "['T0191.jpg', 0.1532806]\n",
      "['T0052.jpg', 0.01321236]\n",
      "['T0257.jpg', 0.0057088025]\n",
      "['T0058.jpg', 0.9983205]\n",
      "['T0300.jpg', 0.9974607]\n",
      "['T0003.jpg', 0.0043857438]\n",
      "['T0320.jpg', 0.9981256]\n",
      "['T0107.jpg', 0.9992514]\n",
      "['T0116.jpg', 0.9803334]\n",
      "['T0014.jpg', 0.6884365]\n",
      "['T0339.jpg', 0.0061481446]\n",
      "['T0154.jpg', 0.99266523]\n",
      "['T0196.jpg', 0.994589]\n",
      "['T0229.jpg', 0.0048347204]\n",
      "['T0017.jpg', 0.0026218523]\n",
      "['T0390.jpg', 0.011126147]\n",
      "['T0243.jpg', 0.008060478]\n",
      "['T0038.jpg', 0.6177471]\n",
      "['T0016.jpg', 0.00441275]\n",
      "['T0194.jpg', 0.9956103]\n",
      "['T0394.jpg', 0.99833244]\n",
      "['T0302.jpg', 0.014148602]\n",
      "['T0347.jpg', 0.99758327]\n",
      "['T0046.jpg', 0.0036037536]\n",
      "['T0368.jpg', 0.9227473]\n",
      "['T0244.jpg', 0.9528649]\n",
      "['T0086.jpg', 0.9896633]\n",
      "['T0162.jpg', 0.0045882263]\n",
      "['T0077.jpg', 0.006214863]\n",
      "['T0311.jpg', 0.9877089]\n",
      "['T0220.jpg', 0.011100484]\n",
      "['T0177.jpg', 0.992765]\n",
      "['T0332.jpg', 0.9996418]\n",
      "['T0343.jpg', 0.0051495414]\n",
      "['T0063.jpg', 0.056755695]\n",
      "['T0224.jpg', 0.45970237]\n",
      "['T0183.jpg', 0.8464283]\n",
      "['T0131.jpg', 0.9672645]\n",
      "['T0056.jpg', 0.18865064]\n",
      "['T0226.jpg', 0.008441893]\n",
      "['T0365.jpg', 0.009974741]\n",
      "['T0119.jpg', 0.011128733]\n",
      "['T0157.jpg', 0.01163658]\n",
      "['T0246.jpg', 0.9987225]\n",
      "['T0272.jpg', 0.99891126]\n",
      "['T0111.jpg', 0.22821175]\n",
      "['T0076.jpg', 0.011173794]\n",
      "['T0060.jpg', 0.007978094]\n",
      "['T0115.jpg', 0.98401904]\n",
      "['T0350.jpg', 0.95744276]\n",
      "['T0287.jpg', 0.04507955]\n",
      "['T0067.jpg', 0.9595393]\n",
      "['T0011.jpg', 0.0107444525]\n",
      "['T0273.jpg', 0.98901945]\n",
      "['T0029.jpg', 0.98273057]\n",
      "['T0126.jpg', 0.9688497]\n",
      "['T0094.jpg', 0.58779633]\n",
      "['T0022.jpg', 0.004218383]\n",
      "['T0392.jpg', 0.9749867]\n",
      "['T0222.jpg', 0.9992256]\n",
      "['T0372.jpg', 0.993417]\n",
      "['T0166.jpg', 0.9904597]\n",
      "['T0065.jpg', 0.38661996]\n",
      "['T0336.jpg', 0.823553]\n",
      "['T0317.jpg', 0.18554732]\n",
      "['T0268.jpg', 0.9969607]\n",
      "['T0236.jpg', 0.31083408]\n",
      "['T0299.jpg', 0.99831736]\n",
      "['T0137.jpg', 0.27976725]\n",
      "['T0180.jpg', 0.9179091]\n",
      "['T0174.jpg', 0.9984421]\n",
      "['T0310.jpg', 0.115119815]\n",
      "['T0252.jpg', 0.057157062]\n",
      "['T0104.jpg', 0.0020662418]\n",
      "['T0265.jpg', 0.0043578898]\n",
      "['T0327.jpg', 0.8923389]\n",
      "['T0213.jpg', 0.99195147]\n",
      "['T0133.jpg', 0.99509984]\n",
      "['T0217.jpg', 0.009684031]\n",
      "['T0298.jpg', 0.0020390237]\n",
      "['T0178.jpg', 0.99853814]\n",
      "['T0044.jpg', 0.008103988]\n",
      "['T0059.jpg', 0.9991177]\n",
      "['T0004.jpg', 0.9052263]\n",
      "['T0328.jpg', 0.005227383]\n",
      "['T0238.jpg', 0.94099295]\n",
      "['T0095.jpg', 0.031126041]\n",
      "['T0397.jpg', 0.9694817]\n",
      "['T0376.jpg', 0.021444228]\n",
      "['T0374.jpg', 0.9680766]\n",
      "['T0296.jpg', 0.0030569737]\n",
      "['T0291.jpg', 0.12017905]\n",
      "['T0033.jpg', 0.0071240864]\n",
      "['T0175.jpg', 0.99831367]\n",
      "['T0267.jpg', 0.006684158]\n",
      "['T0050.jpg', 0.94432956]\n",
      "['T0165.jpg', 0.007277115]\n",
      "['T0234.jpg', 0.15354624]\n",
      "['T0105.jpg', 0.8754398]\n",
      "['T0322.jpg', 0.0081403935]\n",
      "['T0351.jpg', 0.99646217]\n",
      "['T0242.jpg', 0.8488063]\n",
      "['T0141.jpg', 0.97534674]\n",
      "['T0254.jpg', 0.0018125826]\n",
      "['T0019.jpg', 0.0037111046]\n",
      "['T0284.jpg', 0.0033336575]\n",
      "['T0009.jpg', 0.9777526]\n",
      "['T0227.jpg', 0.9930681]\n",
      "['T0216.jpg', 0.0022066159]\n",
      "['T0307.jpg', 0.011044522]\n",
      "['T0279.jpg', 0.9995515]\n",
      "['T0179.jpg', 0.0031708104]\n",
      "['T0269.jpg', 0.0024888334]\n",
      "['T0212.jpg', 0.010725692]\n",
      "['T0400.jpg', 0.99825376]\n",
      "['T0377.jpg', 0.00887763]\n",
      "['T0391.jpg', 0.044397797]\n",
      "['T0301.jpg', 0.004966499]\n",
      "['T0385.jpg', 0.007622443]\n",
      "['T0182.jpg', 0.9897413]\n",
      "['T0112.jpg', 0.004749007]\n",
      "['T0012.jpg', 0.9995516]\n",
      "['T0085.jpg', 0.99860007]\n",
      "['T0219.jpg', 0.10407087]\n",
      "['T0096.jpg', 0.00621358]\n",
      "['T0025.jpg', 0.0060505695]\n",
      "['T0181.jpg', 0.9996586]\n",
      "['T0313.jpg', 0.018776411]\n",
      "['T0047.jpg', 0.013980207]\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import paddle.vision.transforms as T\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.nn.functional as F\r\n",
    "from ppim import DistilledVisionTransformer\r\n",
    "\r\n",
    "save_path = '10.0.csv'\r\n",
    "file_path = 'PLAM/PALM-Testing400-Images'\r\n",
    "imgs_name = os.listdir(file_path)\r\n",
    "\r\n",
    "model = DistilledVisionTransformer(\r\n",
    "    img_size=1120,\r\n",
    "    patch_size=64,\r\n",
    "    class_dim=2)\r\n",
    "params = paddle.load('save_models7/20.pdparams')\r\n",
    "model.set_state_dict(params)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "inf_transforms = T.Compose([\r\n",
    "    # T.Resize((1024, 1024), interpolation='bicubic'),\r\n",
    "    # T.ColorJitter(0.1, 0.1, 0.1, 0.1),\r\n",
    "    # T.RandomHorizontalFlip(),\r\n",
    "    # T.RandomRotation(90),\r\n",
    "   \t# T.ToTensor()\r\n",
    "    T.Resize((1120, 1120), interpolation='bicubic'),  # 1120X1120\r\n",
    "    T.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "pre_data = []\r\n",
    "for img_name in imgs_name:\r\n",
    "    data_path = os.path.join(file_path, img_name)\r\n",
    "    data = np.asarray(Image.open(data_path).convert('RGB'))\r\n",
    "    data = inf_transforms(data)\r\n",
    "    data = data.astype('float32').reshape([1, 3, 1120, 1120])\r\n",
    "    pre = model(data)\r\n",
    "    pre = F.softmax(pre)\r\n",
    "    print([img_name, pre.numpy()[0][1]])\r\n",
    "    pre_data.append([img_name, pre.numpy()[0][1]])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['T0001.jpg', 0.99403954], ['T0002.jpg', 0.008706468], ['T0003.jpg', 0.0043857438], ['T0004.jpg', 0.9052263], ['T0005.jpg', 0.99958795], ['T0006.jpg', 0.032943066], ['T0007.jpg', 0.9691701], ['T0008.jpg', 0.9956103], ['T0009.jpg', 0.9777526], ['T0010.jpg', 0.9446918], ['T0011.jpg', 0.0107444525], ['T0012.jpg', 0.9995516], ['T0013.jpg', 0.9843315], ['T0014.jpg', 0.6884365], ['T0015.jpg', 0.98728323], ['T0016.jpg', 0.00441275], ['T0017.jpg', 0.0026218523], ['T0018.jpg', 0.9953727], ['T0019.jpg', 0.0037111046], ['T0020.jpg', 0.9926979], ['T0021.jpg', 0.0043539344], ['T0022.jpg', 0.004218383], ['T0023.jpg', 0.99892056], ['T0024.jpg', 0.01631227], ['T0025.jpg', 0.0060505695], ['T0026.jpg', 0.9908313], ['T0027.jpg', 0.022977568], ['T0028.jpg', 0.0064003114], ['T0029.jpg', 0.98273057], ['T0030.jpg', 0.5582529], ['T0031.jpg', 0.032938343], ['T0032.jpg', 0.012693948], ['T0033.jpg', 0.0071240864], ['T0034.jpg', 0.9992411], ['T0035.jpg', 0.99029607], ['T0036.jpg', 0.9984432], ['T0037.jpg', 0.99104017], ['T0038.jpg', 0.6177471], ['T0039.jpg', 0.005910738], ['T0040.jpg', 0.005555278], ['T0041.jpg', 0.9348274], ['T0042.jpg', 0.0036783481], ['T0043.jpg', 0.6406758], ['T0044.jpg', 0.008103988], ['T0045.jpg', 0.010184213], ['T0046.jpg', 0.0036037536], ['T0047.jpg', 0.013980207], ['T0048.jpg', 0.011029246], ['T0049.jpg', 0.004271026], ['T0050.jpg', 0.94432956], ['T0051.jpg', 0.9969121], ['T0052.jpg', 0.01321236], ['T0053.jpg', 0.012088187], ['T0054.jpg', 0.99931216], ['T0055.jpg', 0.9593526], ['T0056.jpg', 0.18865064], ['T0057.jpg', 0.0040142527], ['T0058.jpg', 0.9983205], ['T0059.jpg', 0.9991177], ['T0060.jpg', 0.007978094], ['T0061.jpg', 0.86990035], ['T0062.jpg', 0.31416857], ['T0063.jpg', 0.056755695], ['T0064.jpg', 0.9980636], ['T0065.jpg', 0.38661996], ['T0066.jpg', 0.9962853], ['T0067.jpg', 0.9595393], ['T0068.jpg', 0.005791885], ['T0069.jpg', 0.99961036], ['T0070.jpg', 0.006429946], ['T0071.jpg', 0.8933397], ['T0072.jpg', 0.9770388], ['T0073.jpg', 0.9974681], ['T0074.jpg', 0.99756926], ['T0075.jpg', 0.988863], ['T0076.jpg', 0.011173794], ['T0077.jpg', 0.006214863], ['T0078.jpg', 0.0048059905], ['T0079.jpg', 0.9996364], ['T0080.jpg', 0.96117043], ['T0081.jpg', 0.97668046], ['T0082.jpg', 0.9970697], ['T0083.jpg', 0.014882003], ['T0084.jpg', 0.002748082], ['T0085.jpg', 0.99860007], ['T0086.jpg', 0.9896633], ['T0087.jpg', 0.99949574], ['T0088.jpg', 0.99905545], ['T0089.jpg', 0.02961307], ['T0090.jpg', 0.075160824], ['T0091.jpg', 0.99847704], ['T0092.jpg', 0.9991321], ['T0093.jpg', 0.014209201], ['T0094.jpg', 0.58779633], ['T0095.jpg', 0.031126041], ['T0096.jpg', 0.00621358], ['T0097.jpg', 0.9820868], ['T0098.jpg', 0.006875737], ['T0099.jpg', 0.009157534], ['T0100.jpg', 0.49359265], ['T0101.jpg', 0.9888676], ['T0102.jpg', 0.99894744], ['T0103.jpg', 0.012307137], ['T0104.jpg', 0.0020662418], ['T0105.jpg', 0.8754398], ['T0106.jpg', 0.99573743], ['T0107.jpg', 0.9992514], ['T0108.jpg', 0.0017424703], ['T0109.jpg', 0.9285462], ['T0110.jpg', 0.9398], ['T0111.jpg', 0.22821175], ['T0112.jpg', 0.004749007], ['T0113.jpg', 0.9995338], ['T0114.jpg', 0.909846], ['T0115.jpg', 0.98401904], ['T0116.jpg', 0.9803334], ['T0117.jpg', 0.037716474], ['T0118.jpg', 0.01532629], ['T0119.jpg', 0.011128733], ['T0120.jpg', 0.025499515], ['T0121.jpg', 0.004908861], ['T0122.jpg', 0.99834347], ['T0123.jpg', 0.9760375], ['T0124.jpg', 0.99929154], ['T0125.jpg', 0.008596284], ['T0126.jpg', 0.9688497], ['T0127.jpg', 0.9989631], ['T0128.jpg', 0.0046273167], ['T0129.jpg', 0.0092371395], ['T0130.jpg', 0.99125236], ['T0131.jpg', 0.9672645], ['T0132.jpg', 0.35218227], ['T0133.jpg', 0.99509984], ['T0134.jpg', 0.9990803], ['T0135.jpg', 0.012650938], ['T0136.jpg', 0.9936527], ['T0137.jpg', 0.27976725], ['T0138.jpg', 0.022080075], ['T0139.jpg', 0.99932444], ['T0140.jpg', 0.41833097], ['T0141.jpg', 0.97534674], ['T0142.jpg', 0.8089228], ['T0143.jpg', 0.99773645], ['T0144.jpg', 0.0031895349], ['T0145.jpg', 0.9911226], ['T0146.jpg', 0.74678165], ['T0147.jpg', 0.0055694627], ['T0148.jpg', 0.999198], ['T0149.jpg', 0.003278371], ['T0150.jpg', 0.14695121], ['T0151.jpg', 0.9974043], ['T0152.jpg', 0.6182722], ['T0153.jpg', 0.9829836], ['T0154.jpg', 0.99266523], ['T0155.jpg', 0.9964135], ['T0156.jpg', 0.011284045], ['T0157.jpg', 0.01163658], ['T0158.jpg', 0.98628354], ['T0159.jpg', 0.9938677], ['T0160.jpg', 0.9987942], ['T0161.jpg', 0.0042887377], ['T0162.jpg', 0.0045882263], ['T0163.jpg', 0.009565333], ['T0164.jpg', 0.02227682], ['T0165.jpg', 0.007277115], ['T0166.jpg', 0.9904597], ['T0167.jpg', 0.9949851], ['T0168.jpg', 0.00320495], ['T0169.jpg', 0.0056458474], ['T0170.jpg', 0.9968561], ['T0171.jpg', 0.007894516], ['T0172.jpg', 0.99530596], ['T0173.jpg', 0.66700286], ['T0174.jpg', 0.9984421], ['T0175.jpg', 0.99831367], ['T0176.jpg', 0.99902797], ['T0177.jpg', 0.992765], ['T0178.jpg', 0.99853814], ['T0179.jpg', 0.0031708104], ['T0180.jpg', 0.9179091], ['T0181.jpg', 0.9996586], ['T0182.jpg', 0.9897413], ['T0183.jpg', 0.8464283], ['T0184.jpg', 0.005673417], ['T0185.jpg', 0.013359403], ['T0186.jpg', 0.009532422], ['T0187.jpg', 0.0024519546], ['T0188.jpg', 0.9891818], ['T0189.jpg', 0.012986695], ['T0190.jpg', 0.99441886], ['T0191.jpg', 0.1532806], ['T0192.jpg', 0.00912006], ['T0193.jpg', 0.016092822], ['T0194.jpg', 0.9956103], ['T0195.jpg', 0.024826797], ['T0196.jpg', 0.994589], ['T0197.jpg', 0.005576762], ['T0198.jpg', 0.99354964], ['T0199.jpg', 0.0036549224], ['T0200.jpg', 0.004090931], ['T0201.jpg', 0.44248122], ['T0202.jpg', 0.0029475705], ['T0203.jpg', 0.99945015], ['T0204.jpg', 0.1071738], ['T0205.jpg', 0.01924535], ['T0206.jpg', 0.9365295], ['T0207.jpg', 0.99956673], ['T0208.jpg', 0.99853826], ['T0209.jpg', 0.99929214], ['T0210.jpg', 0.90871423], ['T0211.jpg', 0.99816245], ['T0212.jpg', 0.010725692], ['T0213.jpg', 0.99195147], ['T0214.jpg', 0.0044559627], ['T0215.jpg', 0.0030058057], ['T0216.jpg', 0.0022066159], ['T0217.jpg', 0.009684031], ['T0218.jpg', 0.9934394], ['T0219.jpg', 0.10407087], ['T0220.jpg', 0.011100484], ['T0221.jpg', 0.9944206], ['T0222.jpg', 0.9992256], ['T0223.jpg', 0.9976922], ['T0224.jpg', 0.45970237], ['T0225.jpg', 0.45718023], ['T0226.jpg', 0.008441893], ['T0227.jpg', 0.9930681], ['T0228.jpg', 0.005353403], ['T0229.jpg', 0.0048347204], ['T0230.jpg', 0.048461378], ['T0231.jpg', 0.9990877], ['T0232.jpg', 0.8559369], ['T0233.jpg', 0.03114533], ['T0234.jpg', 0.15354624], ['T0235.jpg', 0.9640827], ['T0236.jpg', 0.31083408], ['T0237.jpg', 0.90604925], ['T0238.jpg', 0.94099295], ['T0239.jpg', 0.40348646], ['T0240.jpg', 0.9979242], ['T0241.jpg', 0.999464], ['T0242.jpg', 0.8488063], ['T0243.jpg', 0.008060478], ['T0244.jpg', 0.9528649], ['T0245.jpg', 0.0027808247], ['T0246.jpg', 0.9987225], ['T0247.jpg', 0.0023256307], ['T0248.jpg', 0.015852554], ['T0249.jpg', 0.041713268], ['T0250.jpg', 0.9972608], ['T0251.jpg', 0.99388677], ['T0252.jpg', 0.057157062], ['T0253.jpg', 0.1409466], ['T0254.jpg', 0.0018125826], ['T0255.jpg', 0.0028884285], ['T0256.jpg', 0.9978497], ['T0257.jpg', 0.0057088025], ['T0258.jpg', 0.013071186], ['T0259.jpg', 0.009702688], ['T0260.jpg', 0.9955537], ['T0261.jpg', 0.9983719], ['T0262.jpg', 0.008459427], ['T0263.jpg', 0.98573107], ['T0264.jpg', 0.99188095], ['T0265.jpg', 0.0043578898], ['T0266.jpg', 0.95396376], ['T0267.jpg', 0.006684158], ['T0268.jpg', 0.9969607], ['T0269.jpg', 0.0024888334], ['T0270.jpg', 0.9877489], ['T0271.jpg', 0.88482565], ['T0272.jpg', 0.99891126], ['T0273.jpg', 0.98901945], ['T0274.jpg', 0.0019926443], ['T0275.jpg', 0.9008998], ['T0276.jpg', 0.99175006], ['T0277.jpg', 0.0075759506], ['T0278.jpg', 0.99712855], ['T0279.jpg', 0.9995515], ['T0280.jpg', 0.005168128], ['T0281.jpg', 0.0027148237], ['T0282.jpg', 0.99927217], ['T0283.jpg', 0.0026753393], ['T0284.jpg', 0.0033336575], ['T0285.jpg', 0.027035022], ['T0286.jpg', 0.041713268], ['T0287.jpg', 0.04507955], ['T0288.jpg', 0.9986797], ['T0289.jpg', 0.81314903], ['T0290.jpg', 0.0032549826], ['T0291.jpg', 0.12017905], ['T0292.jpg', 0.010027099], ['T0293.jpg', 0.4904263], ['T0294.jpg', 0.0034201415], ['T0295.jpg', 0.012408653], ['T0296.jpg', 0.0030569737], ['T0297.jpg', 0.20527397], ['T0298.jpg', 0.0020390237], ['T0299.jpg', 0.99831736], ['T0300.jpg', 0.9974607], ['T0301.jpg', 0.004966499], ['T0302.jpg', 0.014148602], ['T0303.jpg', 0.9970797], ['T0304.jpg', 0.0076878434], ['T0305.jpg', 0.006247103], ['T0306.jpg', 0.9989856], ['T0307.jpg', 0.011044522], ['T0308.jpg', 0.011607478], ['T0309.jpg', 0.0058495114], ['T0310.jpg', 0.115119815], ['T0311.jpg', 0.9877089], ['T0312.jpg', 0.9796642], ['T0313.jpg', 0.018776411], ['T0314.jpg', 0.9893056], ['T0315.jpg', 0.9996402], ['T0316.jpg', 0.014468454], ['T0317.jpg', 0.18554732], ['T0318.jpg', 0.07624159], ['T0319.jpg', 0.998348], ['T0320.jpg', 0.9981256], ['T0321.jpg', 0.9940409], ['T0322.jpg', 0.0081403935], ['T0323.jpg', 0.014455602], ['T0324.jpg', 0.043156046], ['T0325.jpg', 0.99018186], ['T0326.jpg', 0.8106482], ['T0327.jpg', 0.8923389], ['T0328.jpg', 0.005227383], ['T0329.jpg', 0.99448806], ['T0330.jpg', 0.0064832186], ['T0331.jpg', 0.0023279174], ['T0332.jpg', 0.9996418], ['T0333.jpg', 0.0065847537], ['T0334.jpg', 0.014079788], ['T0335.jpg', 0.005843663], ['T0336.jpg', 0.823553], ['T0337.jpg', 0.011126147], ['T0338.jpg', 0.9848583], ['T0339.jpg', 0.0061481446], ['T0340.jpg', 0.99088824], ['T0341.jpg', 0.9996692], ['T0342.jpg', 0.9625817], ['T0343.jpg', 0.0051495414], ['T0344.jpg', 0.9908296], ['T0345.jpg', 0.9953497], ['T0346.jpg', 0.99016273], ['T0347.jpg', 0.99758327], ['T0348.jpg', 0.014048084], ['T0349.jpg', 0.94388616], ['T0350.jpg', 0.95744276], ['T0351.jpg', 0.99646217], ['T0352.jpg', 0.9854972], ['T0353.jpg', 0.9564352], ['T0354.jpg', 0.9984518], ['T0355.jpg', 0.22488086], ['T0356.jpg', 0.99967635], ['T0357.jpg', 0.0054225056], ['T0358.jpg', 0.0042363764], ['T0359.jpg', 0.98856807], ['T0360.jpg', 0.9947523], ['T0361.jpg', 0.00599946], ['T0362.jpg', 0.00707871], ['T0363.jpg', 0.0060812817], ['T0364.jpg', 0.99578214], ['T0365.jpg', 0.009974741], ['T0366.jpg', 0.059233658], ['T0367.jpg', 0.97292185], ['T0368.jpg', 0.9227473], ['T0369.jpg', 0.9966748], ['T0370.jpg', 0.9222939], ['T0371.jpg', 0.9986505], ['T0372.jpg', 0.993417], ['T0373.jpg', 0.82973117], ['T0374.jpg', 0.9680766], ['T0375.jpg', 0.99264], ['T0376.jpg', 0.021444228], ['T0377.jpg', 0.00887763], ['T0378.jpg', 0.9318351], ['T0379.jpg', 0.32696337], ['T0380.jpg', 0.99453235], ['T0381.jpg', 0.003037737], ['T0382.jpg', 0.009729083], ['T0383.jpg', 0.015317332], ['T0384.jpg', 0.0019926557], ['T0385.jpg', 0.007622443], ['T0386.jpg', 0.0063389153], ['T0387.jpg', 0.99814475], ['T0388.jpg', 0.99704665], ['T0389.jpg', 0.016682131], ['T0390.jpg', 0.011126147], ['T0391.jpg', 0.044397797], ['T0392.jpg', 0.9749867], ['T0393.jpg', 0.98954517], ['T0394.jpg', 0.99833244], ['T0395.jpg', 0.996064], ['T0396.jpg', 0.9985089], ['T0397.jpg', 0.9694817], ['T0398.jpg', 0.9990043], ['T0399.jpg', 0.004941897], ['T0400.jpg', 0.99825376]]\n"
     ]
    }
   ],
   "source": [
    "new_data = sorted(pre_data)\r\n",
    "\r\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**生成结果文件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_data, columns=['FileName', 'PM Risk'])\r\n",
    "df.to_csv(save_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **六、结果分析**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "近视预测：\n",
    "\n",
    "lr=3e-6（原始学习率）\n",
    "\n",
    "1024x1024：\n",
    "\n",
    "Adam-100-0.9596\n",
    "\n",
    "Adam-100+SGD-50-0.9540\n",
    "\n",
    "1120x1120：\n",
    "\n",
    "Adam-50-0.97442(预测1120)\n",
    "\n",
    "Adam-50-0.97514(预测1024)\n",
    "\n",
    "发现1120x1120准确率都比较高，因此用1120x1120尺寸，用不同学习率lr，以及不同优化器进行训练\n",
    "\n",
    "lr=0.0000125\n",
    "\n",
    "Adam-100：\n",
    "\n",
    "1120x1120,+垂直反转:0.99132(预测1024)\n",
    "\n",
    "1120x1120,+垂直反转:**0.99202**(预测1120)\n",
    "\n",
    "Adam-100+SGD-60:0.99152\n",
    "\n",
    "Adam-100：\n",
    "\n",
    "1120x1120，再+transforms.RandomRotation(90),#随机旋转，：**0.99204**\n",
    "\n",
    "Adam-100+sgd-30：\n",
    "\n",
    "1120x1120，再+transforms.RandomRotation(90),#随机旋转，：**0.99214**\n",
    "\n",
    "结果融合：**0.99232**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **七、创新点：结果融合**（能够提一点分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**注意事项：**\n",
    "\n",
    "进行结果融合的模型，模型精度理应相近不能差别太大，否则融合模型精度会低于最优单一模型精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "df1=pd.read_csv('6.0.csv')\r\n",
    "df2=pd.read_csv('9.0+sgd.csv')\r\n",
    "# df3=pd.read_csv('10.0.csv')\r\n",
    "dfs=[df1,df2]\r\n",
    "PM_Risk=[]\r\n",
    "File_Name=[]\r\n",
    "\r\n",
    "for i in range(len(df1)):\r\n",
    "    File_Name.append(dfs[0]['FileName'][i])\r\n",
    "    avg=(sum(np.array(dfs[x]['PM Risk'][i]) for x in range(len(dfs))))/len(dfs)\r\n",
    "  \r\n",
    "    \r\n",
    "    PM_Risk.append(avg)\r\n",
    "\r\n",
    "submission = pd.DataFrame(data={\r\n",
    "                            \"FileName\": File_Name,\r\n",
    "                            \"PM Risk\": PM_Risk\r\n",
    "                        })\r\n",
    "submission=submission.sort_values(by='FileName')\r\n",
    "submission.to_csv(\"resultx2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 八、分析总结\n",
    "\n",
    "1.提高图片尺寸，相应的可以提高预测精度\n",
    "\n",
    "2.传统的数据增强是增分的稳定点，需要多加尝试\n",
    "\n",
    "3.可以进一步尝试不同的优化器和学习率衰减函数结合\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "## **病理性近视预测相关论文**\n",
    "\n",
    "1、 [PPIM](https://github.com/AgentMaker/Paddle-Image-Models)\n",
    "\n",
    "2、https://www.sciencedirect.com/science/article/pii/S0169260720317533\n",
    "\n",
    "3、https://ieeexplore.ieee.org/abstract/document/8929252/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
